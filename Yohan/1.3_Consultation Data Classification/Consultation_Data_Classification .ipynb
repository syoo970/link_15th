{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2seq(text,pos=\"Noun\"):\n",
    "    malist = twitter.pos(text)\n",
    "    res_list = []\n",
    "    for word in malist:\n",
    "        if word[1] == pos:\n",
    "            res_list.append(word[0])\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Yohan\\anaconda3\\envs\\tensorflow_lab\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "# 소비자상담데이터 읽어오기    \n",
    "fp = codecs.open(\"yang.txt\", \"r\")\n",
    "lines = fp.readlines()\n",
    "twitter = Twitter()\n",
    "word_dic = {}\n",
    "fp.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사,부사,형용사,동사만 골라내고 나머지는 버린다. \n",
    "for line in lines:\n",
    "    malist = twitter.pos(line)\n",
    "    for word in malist:\n",
    "        if word[1] in [\"Noun\" , \"Adjective\" , \"Verb\" , 'Adverb']:\n",
    "            if not (word[0] in word_dic):\n",
    "                word_dic[word[0]] = 0\n",
    "            word_dic[word[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배송(99) 배달(36) 주문(33) 변경(31) 되나요(22) 가방(21) 오늘(20) 주(17) 해서(16) 했는데(15) 요(15) 신청(15) 취소(15) 우유(14) 하루(14) 해주세요(13) 제(13) 개(13) 도시락(13) 두유(12) 언제(12) 문의(12) 좀(11) 수(11) 다이어트(11) 혹시(10) 상품(10) 부탁드립니다(9) 어떻게(9) 건가(9) 분유(9) 싶습니다(9) 가요(9) 식품(9) 시작(9) 시(9) 제품(9) 받아(9) 확인(8) 주소(8) 먹어도(8) 메뉴(8) 내일(7) 시간(7) 알(7) 있나요(7) 월(7) 때(7) 번(7) 합니다(7) 배송지(7) 개월(7) 가능한가요(7) 날짜(7) 안(7) 하는데(6) 아기(6) 세트(6) 구입(6) 회사(6) 추가(6) 프로그램(6) 구매(6) 된(6) 같이(6) 날(6) 너무(6) 드립니다(6) 잘(6) 그럼(6) 다(6) 하면(6) 왜(5) 꼭(5) 거(5) 택배(5) 것(5) 미(5) 가능할까(5) 앞(5) 를(5) 정기(5) 할(5) 결제(5) 커피(5) 현관(5) 더(5) 했습니다(5) 그냥(5) 되는건(5) 이번(5) 한번(5) 처음(5) 월요일(5) 일(5) 건지(4) 오는(4) 없이(4) 왔는데(4) 집(4) 총(4) 같은(4) 안녕하세요(4) 하려면(4) 쇼핑몰(4) 하나요(4) 체험(4) 요청(4) 뒤(4) 때문(4) 보(4) 다음(4) 부터(4) 초기(4) 해(4) 도착(4) 종료(4) 식단(4) 는걸(4) 지방(4) 있을까요(4) 두부(4) 출근(3) 이후(3) 사람(3) 이전(3) 이벤트(3) 어디(3) 지역(3) 안되나요(3) 부탁드려요(3) 왔습니다(3) 기존(3) 왔어요(3) 어제(3) 무료(3) 샘플(3) 받고(3) 지금(3) 받게(3) 이미(3) 해야(3) 된건(3) 진행(3) 중(3) 문자(3) 홈페이지(3) 없나요(3) 공휴일(3) 방금(3) 했는데요(3) 입니다(3) 만(3) 설탕(3) 환불(3) 감량(3) 아래(3) 받는(3) 매일(3) 다음주(3) 받을(3) 기간(3) 일회용(3) 달(3) 부분(3) 빠른(3) 오나요(3) 하여(3) 기분(3) 같아요(3) 될까(3) 같은데요(3) 현재(3) 하려고(3) 외부(3) 하나(3) 휴무(3) 화요일(3) 담당자(3) 이메일(3) 수금(3) 싶어요(3) 경우(3) 격일(3) 마트(3) 아이(3) 인형(3) 구(3) 이제(2) 받아줄(2) 없고(2) 아침(2) 아직도(2) 전(2) 없어서요(2) 가지(2) 금일(2) 요망(2) 아니라고(2) 보내주시면(2) 경기도(2) 중단(2) 요거트(2) 일자(2) 원합니다(2) 주치(2) 주기(2) 금(2) 화(2) 않고(2) 위(2) 주세요(2) 저(2) 와요(2) 동안(2) 또(2) 역(2) 머신(2) 종류(2) 받으면(2) 해야하나요(2) 공동(2) 비밀번호(2) 카페라떼(2) 먹었는데(2) 저희(2) 했고(2) 보니(2) 함량(2) 있습니다(2) 다른(2) 대체(2) 아직(2) 않았습니다(2) 사서(2) 물질(2) 애기(2) 입력(2) 언니(2) 한다고(2) 있는데(2) 오류(2) 수정(2) 안됩니다(2) 곳(2) 드려요(2) 마지막(2) 이마트(2) 떡(2) 먹는데(2) 하고싶은데(2) 아까(2) 했던(2) 아니면(2) 걸어놓으면(2) 분(2) 남은(2) 자꾸(2) 겹(2) 있으면(2) 어디서(2) 연락(2) 가능한(2) 받나요(2) 일정(2) 가입(2) 그동안(2) 건강(2) 먹었습니다(2) 제대로(2) 유용하게(2) 알기(2) 론(2) 상태(2) 같은데(2) 못(2) 그(2) 쭉(2) 샐러드(2) 하지(2) 온거(2) 사은(2) 먹고(2) 있는데요(2) 휴가(2) 안해(2) 지정(2) 건너(2) 띄고(2) 하고(2) 휴일(2) 몰에서(2) 동일한(2) 할께요(2) 라서(2) 매우(2) 죄송해요(2) 음식(2) 왔네요(2) 며칠(2) 불만(2) 딸기(2) 바나나(2) 양배추(2) 알림(2) 답변(2) 수요일(2) 캡슐(2) 팩(2) 유통(2) 기한(2) 말씀(2) 달동(2) 후(2) 단계(2) 있는(2) 나눠서(2) 없었습니다(2) 일주일(2) 약정(2) 가장(2) 살(2) 알러지(2) 대형(2) 판매(2) 이렇게(2) 하려고하는데요(2) 글(2) 하였는데(2) 없다고(2) 게(2) 오고(2) 알려주세요(2) 바로(2) 토마스(2) 주말(2) 유모차(2) 받았는데요(2) 않았어요(2) 아닌가요(2) 반찬(2) 일로(2) 문건(2) 킨(1) 모르겠네요(1) 해야하는데(1) 되는거라면(1) 그대로(1) 버려지겠네요(1) 안되어있습니다(1) 제발(1) 지켜주세요(1) 늦어도(1) 해봤더니(1) 당첨(1) 되었는데요(1) 같던데(1) 차주(1) 발송(1) 예정(1) 데(1) 적은(1) 적(1) 휴대폰(1) 번호(1) 보내주시는(1) 해서요(1) 맞게(1) 돼요(1) 로봇청소기(1) 학생(1) 책상(1) 가능(1) 이천시(1) 가능한지(1) 오프라인(1) 처(1) 의합(1) 니(1) 해당(1) 되었습니다(1) 침대(1) 연기(1) 해주세오(1) 짜리(1) 스케줄(1) 목(1) 로(1) 놔두지(1) 하실(1) 세탁기(1) 놓고(1) 가(1) 안오나요(1) 건(1) 한(1) 싶은건데(1) 되었네요(1) 하우(1) 온라인(1) 중복(1) 되었는데(1) 완료(1) 에러(1) 났어요(1) 카드(1) 되었다고(1) 뭐(1) 있어요(1) 끝나나요(1) 있어서요(1) 했어요(1) 되겠죠(1) 목동(1) 받기로(1) 애가(1) 먹던것보다(1) 향(1) 진해서(1) 약한(1) 하길(1) 희망(1) 먹여도(1) 성분(1) 과(1) 최근(1) 속성(1) 중요한데(1) 되니(1) 의욕(1) 사라지네요(1) 되지(1) 순두부(1) 주는데(1) 나왔습니다(1) 교환(1) 또한(1) 하려는데(1) 안되요(1) 월계동(1) 나옵니다(1) 집중(1) 전자렌지(1) 없는데(1) 차갑고(1) 맛(1) 떨어져도(1) 섭취(1) 되긴(1) 하는거죠(1) 라떼(1) 당뇨(1) 환자(1) 괜찮은(1) 동생(1) 먹이려니(1) 나와서요(1) 어찌(1) 하다가(1) 난(1) 예전(1) 주일(1) 미뤄서(1) 받았으면(1) 미룰수있나요(1) 여긴(1) 서울(1) 창(1) 동점(1) 떡볶이(1) 점심(1) 통과(1) 머리카락(1) 나왔어요(1) 일요일(1) 제주도(1) 여행(1) 일주(1) 일치(1) 부경(1) 김동수(1) 죄송하지만(1) 내주신다(1) 낼(1) 수욜(1) 토욜(1) 담주에(1) 주셔도(1) 감사히(1) 받겠습니다(1) 하며(1) 먹을거라고(1) 말씀드렸었는데(1) 된가요(1) 식(1) 받았습니다(1) 기대했던것과(1) 달라(1) 받던지(1) 받고자(1) 원해요(1) 개발(1) 계획(1) 퀄리티(1) 좋아(1) 만족스러워(1) 꾸준히(1) 먹고싶은데(1) 가짓수(1) 적어(1) 치니(1) 아쉽네요(1) 정해졌는데(1) 받고싶어요(1) 텀(1) 생겨서요(1) 꺼내놓기(1) 힘들어서(1) 종이가방(1) 가능하다해(1) 내(1) 구리시(1) 호로(1) 아파트(1) 비번(1) 없던데(1) 먹일려고(1) 딱(1) 준비(1) 식물성(1) 유산균(1) 쌀(1) 은색(1) 들어가있습니다(1) 색(1) 똑같아서(1) 뚜껑(1) 열어(1) 버렸습니다(1) 말씀드려야하나요(1) 됐어요(1) 신랑(1) 이름(1) 시켰는데(1) 카톡(1) 가능하게(1) 편식(1) 심하고(1) 낳고(1) 갖춰(1) 먹지(1) 끝났는데(1) 더러워요(1) 사용(1) 있을(1) 좋네요(1) 여유(1) 해주시고(1) 주셨는데(1) 제일(1) 깨끗한(1) 이어서(1) 먹었어서(1) 두번째(1) 모든(1) 오이(1) 뺄(1) 문(1) 걸어(1) 두면(1) 하던(1) 시키면(1) 주는(1) 되었나요(1) 받다가(1) 받았어요(1) 왔구요(1) 원래(1) 연달(1) 서(1) 맞는거(1) 다시(1) 되는(1) 품주는것도(1) 인해(1) 구체(1) 싶은데요(1) 해지(1) 되는걸(1) 볼수있을까요(1) 문후(1) 되는거(1) 맞나요(1) 두(1) 받을께요(1) 용기(1) 깨져있습니다(1) 날카롭게(1) 되있고(1) 조각(1) 먹게(1) 될(1) 위험(1) 있었습니다(1) 이랬다(1) 저랬다(1) 껄(1) 보기(1) 하고요(1) 했구요(1) 드린(1) 바(1) 팀(1) 혹은(1) 오늘아침(1) 맘대로(1) 바뀌어져있네요(1) 월화(1) 목금(1) 해놓았는데(1) 걸(1) 다시주세요(1) 돈(1) 주고(1) 산건데(1) 별로(1) 전달(1) 해주시길(1) 와서(1) 세로(1) 세워져있는(1) 바람(1) 샜음(1) 진짜(1) 짜증나네요(1) 의(1) 알고싶어요(1) 거보(1) 빠져(1) 저지방우유(1) 작일(1) 따로(1) 정도(1) 걸린다(1) 얘기(1) 적혀있었는데(1) 안되어서요(1) 치면(1) 보관(1) 어려울(1) 되는지(1) 임시(1) 생각(1) 했네요(1) 그렇다면(1) 나온(1) 콩나물(1) 밥(1) 심각하게(1) 설익었습니다(1) 생쌀(1) 먹는줄(1) 알았어요(1) 익혀주세요(1) 지점(1) 및(1) 안내(1) 고지(1) 않음(1) 서비스(1) 중간(1) 미뤄지는거죠(1) 유지(1) 이용(1) 표(1) 간식(1) 제공(1) 집앞(1) 야구르트(1) 백안(1) 넣어(1) 두시(1) 가지고가셨네요(1) 이건(1) 무슨(1) 혈행(1) 개선(1) 효과(1) 좋은(1) 맛있나요(1) 카페(1) 망고(1) 사과(1) 쥬스(1) 오기(1) 사항(1) 톡(1) 받아서요(1) 부탁드리겠습니다(1) 받았는데(1) 오는거죠(1) 평일(1) 안되는건(1) 토요일(1) 쯤(1) 오는지(1) 오긴(1) 금주(1) 인하여(1) 됐는데(1) 상의(1) 착오(1) 아닌가(1) 있는대요(1) 소바(1) 행사(1) 용이(1) 받고있고(1) 오전(1) 먹이고있는데(1) 먹으며(1) 양(1) 늘려야(1) 할지(1) 시기(1) 연휴(1) 욜(1) 보는데(1) 문제(1) 없을까요(1) 달이(1) 먹으라고(1) 하셨는데(1) 알아서(1) 바꿔서(1) 놓은(1) 알레르기(1) 첨(1) 이해(1) 잘안가서(1) 그러는데(1) 먹을(1) 먹으라는(1) 몇번(1) 나눠(1) 서라도(1) 먹게하라는(1) 몰라서요(1) 그래서(1) 먹는걸(1) 넘어간다는(1) 저녁(1) 치킨(1) 먹으려고(1) 유기농(1) 계란(1) 해요(1) 쉐이크(1) 품(1) 안오네요(1) 보름(1) 보내준다고(1) 했던것(1) 이틀(1) 대문(1) 대부분(1) 누락(1) 정지(1) 목요일(1) 한꺼(1) 남자(1) 있어서(1) 먹이려는데(1) 어린이집(1) 보내야(1) 푸딩(1) 살아이가(1) 제조(1) 신선하지(1) 토핑(1) 소스(1) 개옴(1) 할려고(1) 인천(1) 아님(1) 받는거예요(1) 몇개(1) 배(1) 송료(1) 브로콜리(1) 음료(1) 받는거(1) 선택(1) 받는거로(1) 하려고하는데(1) 더라구요(1) 그러면(1) 해주시나요(1) 그람(1) 사와서(1) 뜯었는데(1) 터져있네요(1) 찝찝해서(1) 먹지도(1) 하겠구요(1) 이런(1) 남깁니다(1) 폰(1) 남기기(1) 어렵더군요(1) 얼마(1) 청소기(1) 볼(1) 있을지(1) 궁금해서(1) 하는거(1) 할려면(1) 여기(1) 해도(1) 그날(1) 연장(1) 스케쥴(1) 작성(1) 된게(1) 음(1) 뜨네요(1) 날로(1) 했었는데(1) 지나면(1) 자동(1) 상세(1) 되는데요(1) 원룸(1) 거주(1) 하는데요(1) 건물(1) 두고(1) 방문(1) 옮기고(1) 기사(1) 초인종(1) 누르면(1) 여(1) 방법(1) 바꾸고(1) 늦은(1) 새벽(1) 상관없어요(1) 상자(1) 첫(1) 전날(1) 미리(1) 당일(1) 싶은데(1) 사이트(1) 접속(1) 하니(1) 계속(1) 나서요(1) 예정일(1) 뜹니다(1) 답답(1) 좋아하는(1) 할수(1) 사촌언니(1) 네사(1) 얻어(1) 좋아해서(1) 끌어안고(1) 타고(1) 나갔다가(1) 떨어뜨린것(1) 유유(1) 평균(1) 나트륨(1) 네(1) 감사해요(1) 기다릴테니(1) 관련(1) 부서(1) 하셔서(1) 부탁드릴게요(1) 차라리(1) 파는거면(1) 당장(1) 사겠는데(1) 그것(1) 아니라서(1) 하기가(1) 어렵네요(1) 파란(1) 안고다니구(1) 탈때(1) 쥐어주니(1) 타길래(1) 들고(1) 나갔다(1) 그만(1) 그래도(1) 통해(1) 먹고있는데(1) 애용(1) 할테니(1) 알아봐주세요(1) 하게되(1) 면(1) 맨날(1) 노래(1) 부르고(1) 다닐게요(1) 정말(1) 감사합니다(1) 박스(1) 중지(1) 오질(1) 되는게(1) 금요일(1) 있거든요(1) 안된다면(1) 신규(1) 지인(1) 아이디(1) 없으면(1) 할인(1) 사제품(1) 프로(1) 해주던데(1) 이었습니다(1) 포장(1) 뜯고(1) 찍은(1) 사진(1) 가끔(1) 성의(1) 담아(1) 보낼(1) 있더군요(1) 먹다(1) 싸준거(1) 같아서(1) 좋지(1) 제작(1) 과정(1) 그럴수(1) 있겠지만(1) 신경(1) 쓰셔야(1) 할거(1) 거부(1) 바랍니다(1) 잘못(1) 봐두(1) 최종(1) 까지인가요(1) 정확(1) 국내(1) 산(1) 쓰나요(1) 치즈(1) 어떤(1) 되네요(1) 이(1) 포함(1) 말아주세요(1) 요즘(1) 자주(1) 내용물(1) 넘쳐있어요(1) 짜증(1) 이나(1) "
     ]
    }
   ],
   "source": [
    "# 사전 만들기(빈도수 순으로)\n",
    "keys = sorted(word_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "for word, count in keys[:10000]:\n",
    "    print(\"{0}({1}) \".format(word, count), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ('배송', 99)\n",
      "2 ('배달', 36)\n",
      "3 ('주문', 33)\n",
      "4 ('변경', 31)\n",
      "5 ('되나요', 22)\n",
      "6 ('가방', 21)\n",
      "7 ('오늘', 20)\n",
      "8 ('주', 17)\n",
      "9 ('해서', 16)\n",
      "10 ('했는데', 15)\n",
      "11 ('요', 15)\n",
      "12 ('신청', 15)\n",
      "13 ('취소', 15)\n",
      "14 ('우유', 14)\n",
      "15 ('하루', 14)\n",
      "16 ('해주세요', 13)\n",
      "17 ('제', 13)\n",
      "18 ('개', 13)\n",
      "19 ('도시락', 13)\n",
      "20 ('두유', 12)\n",
      "21 ('언제', 12)\n",
      "22 ('문의', 12)\n",
      "23 ('좀', 11)\n",
      "24 ('수', 11)\n",
      "25 ('다이어트', 11)\n",
      "26 ('혹시', 10)\n",
      "27 ('상품', 10)\n",
      "28 ('부탁드립니다', 9)\n",
      "29 ('어떻게', 9)\n",
      "30 ('건가', 9)\n",
      "31 ('분유', 9)\n",
      "32 ('싶습니다', 9)\n",
      "33 ('가요', 9)\n",
      "34 ('식품', 9)\n",
      "35 ('시작', 9)\n",
      "36 ('시', 9)\n",
      "37 ('제품', 9)\n",
      "38 ('받아', 9)\n",
      "39 ('확인', 8)\n",
      "40 ('주소', 8)\n",
      "41 ('먹어도', 8)\n",
      "42 ('메뉴', 8)\n",
      "43 ('내일', 7)\n",
      "44 ('시간', 7)\n",
      "45 ('알', 7)\n",
      "46 ('있나요', 7)\n",
      "47 ('월', 7)\n",
      "48 ('때', 7)\n",
      "49 ('번', 7)\n",
      "50 ('합니다', 7)\n",
      "51 ('배송지', 7)\n",
      "52 ('개월', 7)\n",
      "53 ('가능한가요', 7)\n",
      "54 ('날짜', 7)\n",
      "55 ('안', 7)\n",
      "56 ('하는데', 6)\n",
      "57 ('아기', 6)\n",
      "58 ('세트', 6)\n",
      "59 ('구입', 6)\n",
      "60 ('회사', 6)\n",
      "61 ('추가', 6)\n",
      "62 ('프로그램', 6)\n",
      "63 ('구매', 6)\n",
      "64 ('된', 6)\n",
      "65 ('같이', 6)\n",
      "66 ('날', 6)\n",
      "67 ('너무', 6)\n",
      "68 ('드립니다', 6)\n",
      "69 ('잘', 6)\n",
      "70 ('그럼', 6)\n",
      "71 ('다', 6)\n",
      "72 ('하면', 6)\n",
      "73 ('왜', 5)\n",
      "74 ('꼭', 5)\n",
      "75 ('거', 5)\n",
      "76 ('택배', 5)\n",
      "77 ('것', 5)\n",
      "78 ('미', 5)\n",
      "79 ('가능할까', 5)\n",
      "80 ('앞', 5)\n",
      "81 ('를', 5)\n",
      "82 ('정기', 5)\n",
      "83 ('할', 5)\n",
      "84 ('결제', 5)\n",
      "85 ('커피', 5)\n",
      "86 ('현관', 5)\n",
      "87 ('더', 5)\n",
      "88 ('했습니다', 5)\n",
      "89 ('그냥', 5)\n",
      "90 ('되는건', 5)\n",
      "91 ('이번', 5)\n",
      "92 ('한번', 5)\n",
      "93 ('처음', 5)\n",
      "94 ('월요일', 5)\n",
      "95 ('일', 5)\n",
      "96 ('건지', 4)\n",
      "97 ('오는', 4)\n",
      "98 ('없이', 4)\n",
      "99 ('왔는데', 4)\n",
      "100 ('집', 4)\n",
      "101 ('총', 4)\n",
      "102 ('같은', 4)\n",
      "103 ('안녕하세요', 4)\n",
      "104 ('하려면', 4)\n",
      "105 ('쇼핑몰', 4)\n",
      "106 ('하나요', 4)\n",
      "107 ('체험', 4)\n",
      "108 ('요청', 4)\n",
      "109 ('뒤', 4)\n",
      "110 ('때문', 4)\n",
      "111 ('보', 4)\n",
      "112 ('다음', 4)\n",
      "113 ('부터', 4)\n",
      "114 ('초기', 4)\n",
      "115 ('해', 4)\n",
      "116 ('도착', 4)\n",
      "117 ('종료', 4)\n",
      "118 ('식단', 4)\n",
      "119 ('는걸', 4)\n",
      "120 ('지방', 4)\n",
      "121 ('있을까요', 4)\n",
      "122 ('두부', 4)\n",
      "123 ('출근', 3)\n",
      "124 ('이후', 3)\n",
      "125 ('사람', 3)\n",
      "126 ('이전', 3)\n",
      "127 ('이벤트', 3)\n",
      "128 ('어디', 3)\n",
      "129 ('지역', 3)\n",
      "130 ('안되나요', 3)\n",
      "131 ('부탁드려요', 3)\n",
      "132 ('왔습니다', 3)\n",
      "133 ('기존', 3)\n",
      "134 ('왔어요', 3)\n",
      "135 ('어제', 3)\n",
      "136 ('무료', 3)\n",
      "137 ('샘플', 3)\n",
      "138 ('받고', 3)\n",
      "139 ('지금', 3)\n",
      "140 ('받게', 3)\n",
      "141 ('이미', 3)\n",
      "142 ('해야', 3)\n",
      "143 ('된건', 3)\n",
      "144 ('진행', 3)\n",
      "145 ('중', 3)\n",
      "146 ('문자', 3)\n",
      "147 ('홈페이지', 3)\n",
      "148 ('없나요', 3)\n",
      "149 ('공휴일', 3)\n",
      "150 ('방금', 3)\n",
      "151 ('했는데요', 3)\n",
      "152 ('입니다', 3)\n",
      "153 ('만', 3)\n",
      "154 ('설탕', 3)\n",
      "155 ('환불', 3)\n",
      "156 ('감량', 3)\n",
      "157 ('아래', 3)\n",
      "158 ('받는', 3)\n",
      "159 ('매일', 3)\n",
      "160 ('다음주', 3)\n",
      "161 ('받을', 3)\n",
      "162 ('기간', 3)\n",
      "163 ('일회용', 3)\n",
      "164 ('달', 3)\n",
      "165 ('부분', 3)\n",
      "166 ('빠른', 3)\n",
      "167 ('오나요', 3)\n",
      "168 ('하여', 3)\n",
      "169 ('기분', 3)\n",
      "170 ('같아요', 3)\n",
      "171 ('될까', 3)\n",
      "172 ('같은데요', 3)\n",
      "173 ('현재', 3)\n",
      "174 ('하려고', 3)\n",
      "175 ('외부', 3)\n",
      "176 ('하나', 3)\n",
      "177 ('휴무', 3)\n",
      "178 ('화요일', 3)\n",
      "179 ('담당자', 3)\n",
      "180 ('이메일', 3)\n",
      "181 ('수금', 3)\n",
      "182 ('싶어요', 3)\n",
      "183 ('경우', 3)\n",
      "184 ('격일', 3)\n",
      "185 ('마트', 3)\n",
      "186 ('아이', 3)\n",
      "187 ('인형', 3)\n",
      "188 ('구', 3)\n",
      "189 ('이제', 2)\n",
      "190 ('받아줄', 2)\n",
      "191 ('없고', 2)\n",
      "192 ('아침', 2)\n",
      "193 ('아직도', 2)\n",
      "194 ('전', 2)\n",
      "195 ('없어서요', 2)\n",
      "196 ('가지', 2)\n",
      "197 ('금일', 2)\n",
      "198 ('요망', 2)\n",
      "199 ('아니라고', 2)\n",
      "200 ('보내주시면', 2)\n",
      "201 ('경기도', 2)\n",
      "202 ('중단', 2)\n",
      "203 ('요거트', 2)\n",
      "204 ('일자', 2)\n",
      "205 ('원합니다', 2)\n",
      "206 ('주치', 2)\n",
      "207 ('주기', 2)\n",
      "208 ('금', 2)\n",
      "209 ('화', 2)\n",
      "210 ('않고', 2)\n",
      "211 ('위', 2)\n",
      "212 ('주세요', 2)\n",
      "213 ('저', 2)\n",
      "214 ('와요', 2)\n",
      "215 ('동안', 2)\n",
      "216 ('또', 2)\n",
      "217 ('역', 2)\n",
      "218 ('머신', 2)\n",
      "219 ('종류', 2)\n",
      "220 ('받으면', 2)\n",
      "221 ('해야하나요', 2)\n",
      "222 ('공동', 2)\n",
      "223 ('비밀번호', 2)\n",
      "224 ('카페라떼', 2)\n",
      "225 ('먹었는데', 2)\n",
      "226 ('저희', 2)\n",
      "227 ('했고', 2)\n",
      "228 ('보니', 2)\n",
      "229 ('함량', 2)\n",
      "230 ('있습니다', 2)\n",
      "231 ('다른', 2)\n",
      "232 ('대체', 2)\n",
      "233 ('아직', 2)\n",
      "234 ('않았습니다', 2)\n",
      "235 ('사서', 2)\n",
      "236 ('물질', 2)\n",
      "237 ('애기', 2)\n",
      "238 ('입력', 2)\n",
      "239 ('언니', 2)\n",
      "240 ('한다고', 2)\n",
      "241 ('있는데', 2)\n",
      "242 ('오류', 2)\n",
      "243 ('수정', 2)\n",
      "244 ('안됩니다', 2)\n",
      "245 ('곳', 2)\n",
      "246 ('드려요', 2)\n",
      "247 ('마지막', 2)\n",
      "248 ('이마트', 2)\n",
      "249 ('떡', 2)\n",
      "250 ('먹는데', 2)\n",
      "251 ('하고싶은데', 2)\n",
      "252 ('아까', 2)\n",
      "253 ('했던', 2)\n",
      "254 ('아니면', 2)\n",
      "255 ('걸어놓으면', 2)\n",
      "256 ('분', 2)\n",
      "257 ('남은', 2)\n",
      "258 ('자꾸', 2)\n",
      "259 ('겹', 2)\n",
      "260 ('있으면', 2)\n",
      "261 ('어디서', 2)\n",
      "262 ('연락', 2)\n",
      "263 ('가능한', 2)\n",
      "264 ('받나요', 2)\n",
      "265 ('일정', 2)\n",
      "266 ('가입', 2)\n",
      "267 ('그동안', 2)\n",
      "268 ('건강', 2)\n",
      "269 ('먹었습니다', 2)\n",
      "270 ('제대로', 2)\n",
      "271 ('유용하게', 2)\n",
      "272 ('알기', 2)\n",
      "273 ('론', 2)\n",
      "274 ('상태', 2)\n",
      "275 ('같은데', 2)\n",
      "276 ('못', 2)\n",
      "277 ('그', 2)\n",
      "278 ('쭉', 2)\n",
      "279 ('샐러드', 2)\n",
      "280 ('하지', 2)\n",
      "281 ('온거', 2)\n",
      "282 ('사은', 2)\n",
      "283 ('먹고', 2)\n",
      "284 ('있는데요', 2)\n",
      "285 ('휴가', 2)\n",
      "286 ('안해', 2)\n",
      "287 ('지정', 2)\n",
      "288 ('건너', 2)\n",
      "289 ('띄고', 2)\n",
      "290 ('하고', 2)\n",
      "291 ('휴일', 2)\n",
      "292 ('몰에서', 2)\n",
      "293 ('동일한', 2)\n",
      "294 ('할께요', 2)\n",
      "295 ('라서', 2)\n",
      "296 ('매우', 2)\n",
      "297 ('죄송해요', 2)\n",
      "298 ('음식', 2)\n",
      "299 ('왔네요', 2)\n",
      "300 ('며칠', 2)\n",
      "301 ('불만', 2)\n",
      "302 ('딸기', 2)\n",
      "303 ('바나나', 2)\n",
      "304 ('양배추', 2)\n",
      "305 ('알림', 2)\n",
      "306 ('답변', 2)\n",
      "307 ('수요일', 2)\n",
      "308 ('캡슐', 2)\n",
      "309 ('팩', 2)\n",
      "310 ('유통', 2)\n",
      "311 ('기한', 2)\n",
      "312 ('말씀', 2)\n",
      "313 ('달동', 2)\n",
      "314 ('후', 2)\n",
      "315 ('단계', 2)\n",
      "316 ('있는', 2)\n",
      "317 ('나눠서', 2)\n",
      "318 ('없었습니다', 2)\n",
      "319 ('일주일', 2)\n",
      "320 ('약정', 2)\n",
      "321 ('가장', 2)\n",
      "322 ('살', 2)\n",
      "323 ('알러지', 2)\n",
      "324 ('대형', 2)\n",
      "325 ('판매', 2)\n",
      "326 ('이렇게', 2)\n",
      "327 ('하려고하는데요', 2)\n",
      "328 ('글', 2)\n",
      "329 ('하였는데', 2)\n",
      "330 ('없다고', 2)\n",
      "331 ('게', 2)\n",
      "332 ('오고', 2)\n",
      "333 ('알려주세요', 2)\n",
      "334 ('바로', 2)\n",
      "335 ('토마스', 2)\n",
      "336 ('주말', 2)\n",
      "337 ('유모차', 2)\n",
      "338 ('받았는데요', 2)\n",
      "339 ('않았어요', 2)\n",
      "340 ('아닌가요', 2)\n",
      "341 ('반찬', 2)\n",
      "342 ('일로', 2)\n",
      "343 ('문건', 2)\n",
      "344 ('킨', 1)\n",
      "345 ('모르겠네요', 1)\n",
      "346 ('해야하는데', 1)\n",
      "347 ('되는거라면', 1)\n",
      "348 ('그대로', 1)\n",
      "349 ('버려지겠네요', 1)\n",
      "350 ('안되어있습니다', 1)\n",
      "351 ('제발', 1)\n",
      "352 ('지켜주세요', 1)\n",
      "353 ('늦어도', 1)\n",
      "354 ('해봤더니', 1)\n",
      "355 ('당첨', 1)\n",
      "356 ('되었는데요', 1)\n",
      "357 ('같던데', 1)\n",
      "358 ('차주', 1)\n",
      "359 ('발송', 1)\n",
      "360 ('예정', 1)\n",
      "361 ('데', 1)\n",
      "362 ('적은', 1)\n",
      "363 ('적', 1)\n",
      "364 ('휴대폰', 1)\n",
      "365 ('번호', 1)\n",
      "366 ('보내주시는', 1)\n",
      "367 ('해서요', 1)\n",
      "368 ('맞게', 1)\n",
      "369 ('돼요', 1)\n",
      "370 ('로봇청소기', 1)\n",
      "371 ('학생', 1)\n",
      "372 ('책상', 1)\n",
      "373 ('가능', 1)\n",
      "374 ('이천시', 1)\n",
      "375 ('가능한지', 1)\n",
      "376 ('오프라인', 1)\n",
      "377 ('처', 1)\n",
      "378 ('의합', 1)\n",
      "379 ('니', 1)\n",
      "380 ('해당', 1)\n",
      "381 ('되었습니다', 1)\n",
      "382 ('침대', 1)\n",
      "383 ('연기', 1)\n",
      "384 ('해주세오', 1)\n",
      "385 ('짜리', 1)\n",
      "386 ('스케줄', 1)\n",
      "387 ('목', 1)\n",
      "388 ('로', 1)\n",
      "389 ('놔두지', 1)\n",
      "390 ('하실', 1)\n",
      "391 ('세탁기', 1)\n",
      "392 ('놓고', 1)\n",
      "393 ('가', 1)\n",
      "394 ('안오나요', 1)\n",
      "395 ('건', 1)\n",
      "396 ('한', 1)\n",
      "397 ('싶은건데', 1)\n",
      "398 ('되었네요', 1)\n",
      "399 ('하우', 1)\n",
      "400 ('온라인', 1)\n",
      "401 ('중복', 1)\n",
      "402 ('되었는데', 1)\n",
      "403 ('완료', 1)\n",
      "404 ('에러', 1)\n",
      "405 ('났어요', 1)\n",
      "406 ('카드', 1)\n",
      "407 ('되었다고', 1)\n",
      "408 ('뭐', 1)\n",
      "409 ('있어요', 1)\n",
      "410 ('끝나나요', 1)\n",
      "411 ('있어서요', 1)\n",
      "412 ('했어요', 1)\n",
      "413 ('되겠죠', 1)\n",
      "414 ('목동', 1)\n",
      "415 ('받기로', 1)\n",
      "416 ('애가', 1)\n",
      "417 ('먹던것보다', 1)\n",
      "418 ('향', 1)\n",
      "419 ('진해서', 1)\n",
      "420 ('약한', 1)\n",
      "421 ('하길', 1)\n",
      "422 ('희망', 1)\n",
      "423 ('먹여도', 1)\n",
      "424 ('성분', 1)\n",
      "425 ('과', 1)\n",
      "426 ('최근', 1)\n",
      "427 ('속성', 1)\n",
      "428 ('중요한데', 1)\n",
      "429 ('되니', 1)\n",
      "430 ('의욕', 1)\n",
      "431 ('사라지네요', 1)\n",
      "432 ('되지', 1)\n",
      "433 ('순두부', 1)\n",
      "434 ('주는데', 1)\n",
      "435 ('나왔습니다', 1)\n",
      "436 ('교환', 1)\n",
      "437 ('또한', 1)\n",
      "438 ('하려는데', 1)\n",
      "439 ('안되요', 1)\n",
      "440 ('월계동', 1)\n",
      "441 ('나옵니다', 1)\n",
      "442 ('집중', 1)\n",
      "443 ('전자렌지', 1)\n",
      "444 ('없는데', 1)\n",
      "445 ('차갑고', 1)\n",
      "446 ('맛', 1)\n",
      "447 ('떨어져도', 1)\n",
      "448 ('섭취', 1)\n",
      "449 ('되긴', 1)\n",
      "450 ('하는거죠', 1)\n",
      "451 ('라떼', 1)\n",
      "452 ('당뇨', 1)\n",
      "453 ('환자', 1)\n",
      "454 ('괜찮은', 1)\n",
      "455 ('동생', 1)\n",
      "456 ('먹이려니', 1)\n",
      "457 ('나와서요', 1)\n",
      "458 ('어찌', 1)\n",
      "459 ('하다가', 1)\n",
      "460 ('난', 1)\n",
      "461 ('예전', 1)\n",
      "462 ('주일', 1)\n",
      "463 ('미뤄서', 1)\n",
      "464 ('받았으면', 1)\n",
      "465 ('미룰수있나요', 1)\n",
      "466 ('여긴', 1)\n",
      "467 ('서울', 1)\n",
      "468 ('창', 1)\n",
      "469 ('동점', 1)\n",
      "470 ('떡볶이', 1)\n",
      "471 ('점심', 1)\n",
      "472 ('통과', 1)\n",
      "473 ('머리카락', 1)\n",
      "474 ('나왔어요', 1)\n",
      "475 ('일요일', 1)\n",
      "476 ('제주도', 1)\n",
      "477 ('여행', 1)\n",
      "478 ('일주', 1)\n",
      "479 ('일치', 1)\n",
      "480 ('부경', 1)\n",
      "481 ('김동수', 1)\n",
      "482 ('죄송하지만', 1)\n",
      "483 ('내주신다', 1)\n",
      "484 ('낼', 1)\n",
      "485 ('수욜', 1)\n",
      "486 ('토욜', 1)\n",
      "487 ('담주에', 1)\n",
      "488 ('주셔도', 1)\n",
      "489 ('감사히', 1)\n",
      "490 ('받겠습니다', 1)\n",
      "491 ('하며', 1)\n",
      "492 ('먹을거라고', 1)\n",
      "493 ('말씀드렸었는데', 1)\n",
      "494 ('된가요', 1)\n",
      "495 ('식', 1)\n",
      "496 ('받았습니다', 1)\n",
      "497 ('기대했던것과', 1)\n",
      "498 ('달라', 1)\n",
      "499 ('받던지', 1)\n",
      "500 ('받고자', 1)\n",
      "501 ('원해요', 1)\n",
      "502 ('개발', 1)\n",
      "503 ('계획', 1)\n",
      "504 ('퀄리티', 1)\n",
      "505 ('좋아', 1)\n",
      "506 ('만족스러워', 1)\n",
      "507 ('꾸준히', 1)\n",
      "508 ('먹고싶은데', 1)\n",
      "509 ('가짓수', 1)\n",
      "510 ('적어', 1)\n",
      "511 ('치니', 1)\n",
      "512 ('아쉽네요', 1)\n",
      "513 ('정해졌는데', 1)\n",
      "514 ('받고싶어요', 1)\n",
      "515 ('텀', 1)\n",
      "516 ('생겨서요', 1)\n",
      "517 ('꺼내놓기', 1)\n",
      "518 ('힘들어서', 1)\n",
      "519 ('종이가방', 1)\n",
      "520 ('가능하다해', 1)\n",
      "521 ('내', 1)\n",
      "522 ('구리시', 1)\n",
      "523 ('호로', 1)\n",
      "524 ('아파트', 1)\n",
      "525 ('비번', 1)\n",
      "526 ('없던데', 1)\n",
      "527 ('먹일려고', 1)\n",
      "528 ('딱', 1)\n",
      "529 ('준비', 1)\n",
      "530 ('식물성', 1)\n",
      "531 ('유산균', 1)\n",
      "532 ('쌀', 1)\n",
      "533 ('은색', 1)\n",
      "534 ('들어가있습니다', 1)\n",
      "535 ('색', 1)\n",
      "536 ('똑같아서', 1)\n",
      "537 ('뚜껑', 1)\n",
      "538 ('열어', 1)\n",
      "539 ('버렸습니다', 1)\n",
      "540 ('말씀드려야하나요', 1)\n",
      "541 ('됐어요', 1)\n",
      "542 ('신랑', 1)\n",
      "543 ('이름', 1)\n",
      "544 ('시켰는데', 1)\n",
      "545 ('카톡', 1)\n",
      "546 ('가능하게', 1)\n",
      "547 ('편식', 1)\n",
      "548 ('심하고', 1)\n",
      "549 ('낳고', 1)\n",
      "550 ('갖춰', 1)\n",
      "551 ('먹지', 1)\n",
      "552 ('끝났는데', 1)\n",
      "553 ('더러워요', 1)\n",
      "554 ('사용', 1)\n",
      "555 ('있을', 1)\n",
      "556 ('좋네요', 1)\n",
      "557 ('여유', 1)\n",
      "558 ('해주시고', 1)\n",
      "559 ('주셨는데', 1)\n",
      "560 ('제일', 1)\n",
      "561 ('깨끗한', 1)\n",
      "562 ('이어서', 1)\n",
      "563 ('먹었어서', 1)\n",
      "564 ('두번째', 1)\n",
      "565 ('모든', 1)\n",
      "566 ('오이', 1)\n",
      "567 ('뺄', 1)\n",
      "568 ('문', 1)\n",
      "569 ('걸어', 1)\n",
      "570 ('두면', 1)\n",
      "571 ('하던', 1)\n",
      "572 ('시키면', 1)\n",
      "573 ('주는', 1)\n",
      "574 ('되었나요', 1)\n",
      "575 ('받다가', 1)\n",
      "576 ('받았어요', 1)\n",
      "577 ('왔구요', 1)\n",
      "578 ('원래', 1)\n",
      "579 ('연달', 1)\n",
      "580 ('서', 1)\n",
      "581 ('맞는거', 1)\n",
      "582 ('다시', 1)\n",
      "583 ('되는', 1)\n",
      "584 ('품주는것도', 1)\n",
      "585 ('인해', 1)\n",
      "586 ('구체', 1)\n",
      "587 ('싶은데요', 1)\n",
      "588 ('해지', 1)\n",
      "589 ('되는걸', 1)\n",
      "590 ('볼수있을까요', 1)\n",
      "591 ('문후', 1)\n",
      "592 ('되는거', 1)\n",
      "593 ('맞나요', 1)\n",
      "594 ('두', 1)\n",
      "595 ('받을께요', 1)\n",
      "596 ('용기', 1)\n",
      "597 ('깨져있습니다', 1)\n",
      "598 ('날카롭게', 1)\n",
      "599 ('되있고', 1)\n",
      "600 ('조각', 1)\n",
      "601 ('먹게', 1)\n",
      "602 ('될', 1)\n",
      "603 ('위험', 1)\n",
      "604 ('있었습니다', 1)\n",
      "605 ('이랬다', 1)\n",
      "606 ('저랬다', 1)\n",
      "607 ('껄', 1)\n",
      "608 ('보기', 1)\n",
      "609 ('하고요', 1)\n",
      "610 ('했구요', 1)\n",
      "611 ('드린', 1)\n",
      "612 ('바', 1)\n",
      "613 ('팀', 1)\n",
      "614 ('혹은', 1)\n",
      "615 ('오늘아침', 1)\n",
      "616 ('맘대로', 1)\n",
      "617 ('바뀌어져있네요', 1)\n",
      "618 ('월화', 1)\n",
      "619 ('목금', 1)\n",
      "620 ('해놓았는데', 1)\n",
      "621 ('걸', 1)\n",
      "622 ('다시주세요', 1)\n",
      "623 ('돈', 1)\n",
      "624 ('주고', 1)\n",
      "625 ('산건데', 1)\n",
      "626 ('별로', 1)\n",
      "627 ('전달', 1)\n",
      "628 ('해주시길', 1)\n",
      "629 ('와서', 1)\n",
      "630 ('세로', 1)\n",
      "631 ('세워져있는', 1)\n",
      "632 ('바람', 1)\n",
      "633 ('샜음', 1)\n",
      "634 ('진짜', 1)\n",
      "635 ('짜증나네요', 1)\n",
      "636 ('의', 1)\n",
      "637 ('알고싶어요', 1)\n",
      "638 ('거보', 1)\n",
      "639 ('빠져', 1)\n",
      "640 ('저지방우유', 1)\n",
      "641 ('작일', 1)\n",
      "642 ('따로', 1)\n",
      "643 ('정도', 1)\n",
      "644 ('걸린다', 1)\n",
      "645 ('얘기', 1)\n",
      "646 ('적혀있었는데', 1)\n",
      "647 ('안되어서요', 1)\n",
      "648 ('치면', 1)\n",
      "649 ('보관', 1)\n",
      "650 ('어려울', 1)\n",
      "651 ('되는지', 1)\n",
      "652 ('임시', 1)\n",
      "653 ('생각', 1)\n",
      "654 ('했네요', 1)\n",
      "655 ('그렇다면', 1)\n",
      "656 ('나온', 1)\n",
      "657 ('콩나물', 1)\n",
      "658 ('밥', 1)\n",
      "659 ('심각하게', 1)\n",
      "660 ('설익었습니다', 1)\n",
      "661 ('생쌀', 1)\n",
      "662 ('먹는줄', 1)\n",
      "663 ('알았어요', 1)\n",
      "664 ('익혀주세요', 1)\n",
      "665 ('지점', 1)\n",
      "666 ('및', 1)\n",
      "667 ('안내', 1)\n",
      "668 ('고지', 1)\n",
      "669 ('않음', 1)\n",
      "670 ('서비스', 1)\n",
      "671 ('중간', 1)\n",
      "672 ('미뤄지는거죠', 1)\n",
      "673 ('유지', 1)\n",
      "674 ('이용', 1)\n",
      "675 ('표', 1)\n",
      "676 ('간식', 1)\n",
      "677 ('제공', 1)\n",
      "678 ('집앞', 1)\n",
      "679 ('야구르트', 1)\n",
      "680 ('백안', 1)\n",
      "681 ('넣어', 1)\n",
      "682 ('두시', 1)\n",
      "683 ('가지고가셨네요', 1)\n",
      "684 ('이건', 1)\n",
      "685 ('무슨', 1)\n",
      "686 ('혈행', 1)\n",
      "687 ('개선', 1)\n",
      "688 ('효과', 1)\n",
      "689 ('좋은', 1)\n",
      "690 ('맛있나요', 1)\n",
      "691 ('카페', 1)\n",
      "692 ('망고', 1)\n",
      "693 ('사과', 1)\n",
      "694 ('쥬스', 1)\n",
      "695 ('오기', 1)\n",
      "696 ('사항', 1)\n",
      "697 ('톡', 1)\n",
      "698 ('받아서요', 1)\n",
      "699 ('부탁드리겠습니다', 1)\n",
      "700 ('받았는데', 1)\n",
      "701 ('오는거죠', 1)\n",
      "702 ('평일', 1)\n",
      "703 ('안되는건', 1)\n",
      "704 ('토요일', 1)\n",
      "705 ('쯤', 1)\n",
      "706 ('오는지', 1)\n",
      "707 ('오긴', 1)\n",
      "708 ('금주', 1)\n",
      "709 ('인하여', 1)\n",
      "710 ('됐는데', 1)\n",
      "711 ('상의', 1)\n",
      "712 ('착오', 1)\n",
      "713 ('아닌가', 1)\n",
      "714 ('있는대요', 1)\n",
      "715 ('소바', 1)\n",
      "716 ('행사', 1)\n",
      "717 ('용이', 1)\n",
      "718 ('받고있고', 1)\n",
      "719 ('오전', 1)\n",
      "720 ('먹이고있는데', 1)\n",
      "721 ('먹으며', 1)\n",
      "722 ('양', 1)\n",
      "723 ('늘려야', 1)\n",
      "724 ('할지', 1)\n",
      "725 ('시기', 1)\n",
      "726 ('연휴', 1)\n",
      "727 ('욜', 1)\n",
      "728 ('보는데', 1)\n",
      "729 ('문제', 1)\n",
      "730 ('없을까요', 1)\n",
      "731 ('달이', 1)\n",
      "732 ('먹으라고', 1)\n",
      "733 ('하셨는데', 1)\n",
      "734 ('알아서', 1)\n",
      "735 ('바꿔서', 1)\n",
      "736 ('놓은', 1)\n",
      "737 ('알레르기', 1)\n",
      "738 ('첨', 1)\n",
      "739 ('이해', 1)\n",
      "740 ('잘안가서', 1)\n",
      "741 ('그러는데', 1)\n",
      "742 ('먹을', 1)\n",
      "743 ('먹으라는', 1)\n",
      "744 ('몇번', 1)\n",
      "745 ('나눠', 1)\n",
      "746 ('서라도', 1)\n",
      "747 ('먹게하라는', 1)\n",
      "748 ('몰라서요', 1)\n",
      "749 ('그래서', 1)\n",
      "750 ('먹는걸', 1)\n",
      "751 ('넘어간다는', 1)\n",
      "752 ('저녁', 1)\n",
      "753 ('치킨', 1)\n",
      "754 ('먹으려고', 1)\n",
      "755 ('유기농', 1)\n",
      "756 ('계란', 1)\n",
      "757 ('해요', 1)\n",
      "758 ('쉐이크', 1)\n",
      "759 ('품', 1)\n",
      "760 ('안오네요', 1)\n",
      "761 ('보름', 1)\n",
      "762 ('보내준다고', 1)\n",
      "763 ('했던것', 1)\n",
      "764 ('이틀', 1)\n",
      "765 ('대문', 1)\n",
      "766 ('대부분', 1)\n",
      "767 ('누락', 1)\n",
      "768 ('정지', 1)\n",
      "769 ('목요일', 1)\n",
      "770 ('한꺼', 1)\n",
      "771 ('남자', 1)\n",
      "772 ('있어서', 1)\n",
      "773 ('먹이려는데', 1)\n",
      "774 ('어린이집', 1)\n",
      "775 ('보내야', 1)\n",
      "776 ('푸딩', 1)\n",
      "777 ('살아이가', 1)\n",
      "778 ('제조', 1)\n",
      "779 ('신선하지', 1)\n",
      "780 ('토핑', 1)\n",
      "781 ('소스', 1)\n",
      "782 ('개옴', 1)\n",
      "783 ('할려고', 1)\n",
      "784 ('인천', 1)\n",
      "785 ('아님', 1)\n",
      "786 ('받는거예요', 1)\n",
      "787 ('몇개', 1)\n",
      "788 ('배', 1)\n",
      "789 ('송료', 1)\n",
      "790 ('브로콜리', 1)\n",
      "791 ('음료', 1)\n",
      "792 ('받는거', 1)\n",
      "793 ('선택', 1)\n",
      "794 ('받는거로', 1)\n",
      "795 ('하려고하는데', 1)\n",
      "796 ('더라구요', 1)\n",
      "797 ('그러면', 1)\n",
      "798 ('해주시나요', 1)\n",
      "799 ('그람', 1)\n",
      "800 ('사와서', 1)\n",
      "801 ('뜯었는데', 1)\n",
      "802 ('터져있네요', 1)\n",
      "803 ('찝찝해서', 1)\n",
      "804 ('먹지도', 1)\n",
      "805 ('하겠구요', 1)\n",
      "806 ('이런', 1)\n",
      "807 ('남깁니다', 1)\n",
      "808 ('폰', 1)\n",
      "809 ('남기기', 1)\n",
      "810 ('어렵더군요', 1)\n",
      "811 ('얼마', 1)\n",
      "812 ('청소기', 1)\n",
      "813 ('볼', 1)\n",
      "814 ('있을지', 1)\n",
      "815 ('궁금해서', 1)\n",
      "816 ('하는거', 1)\n",
      "817 ('할려면', 1)\n",
      "818 ('여기', 1)\n",
      "819 ('해도', 1)\n",
      "820 ('그날', 1)\n",
      "821 ('연장', 1)\n",
      "822 ('스케쥴', 1)\n",
      "823 ('작성', 1)\n",
      "824 ('된게', 1)\n",
      "825 ('음', 1)\n",
      "826 ('뜨네요', 1)\n",
      "827 ('날로', 1)\n",
      "828 ('했었는데', 1)\n",
      "829 ('지나면', 1)\n",
      "830 ('자동', 1)\n",
      "831 ('상세', 1)\n",
      "832 ('되는데요', 1)\n",
      "833 ('원룸', 1)\n",
      "834 ('거주', 1)\n",
      "835 ('하는데요', 1)\n",
      "836 ('건물', 1)\n",
      "837 ('두고', 1)\n",
      "838 ('방문', 1)\n",
      "839 ('옮기고', 1)\n",
      "840 ('기사', 1)\n",
      "841 ('초인종', 1)\n",
      "842 ('누르면', 1)\n",
      "843 ('여', 1)\n",
      "844 ('방법', 1)\n",
      "845 ('바꾸고', 1)\n",
      "846 ('늦은', 1)\n",
      "847 ('새벽', 1)\n",
      "848 ('상관없어요', 1)\n",
      "849 ('상자', 1)\n",
      "850 ('첫', 1)\n",
      "851 ('전날', 1)\n",
      "852 ('미리', 1)\n",
      "853 ('당일', 1)\n",
      "854 ('싶은데', 1)\n",
      "855 ('사이트', 1)\n",
      "856 ('접속', 1)\n",
      "857 ('하니', 1)\n",
      "858 ('계속', 1)\n",
      "859 ('나서요', 1)\n",
      "860 ('예정일', 1)\n",
      "861 ('뜹니다', 1)\n",
      "862 ('답답', 1)\n",
      "863 ('좋아하는', 1)\n",
      "864 ('할수', 1)\n",
      "865 ('사촌언니', 1)\n",
      "866 ('네사', 1)\n",
      "867 ('얻어', 1)\n",
      "868 ('좋아해서', 1)\n",
      "869 ('끌어안고', 1)\n",
      "870 ('타고', 1)\n",
      "871 ('나갔다가', 1)\n",
      "872 ('떨어뜨린것', 1)\n",
      "873 ('유유', 1)\n",
      "874 ('평균', 1)\n",
      "875 ('나트륨', 1)\n",
      "876 ('네', 1)\n",
      "877 ('감사해요', 1)\n",
      "878 ('기다릴테니', 1)\n",
      "879 ('관련', 1)\n",
      "880 ('부서', 1)\n",
      "881 ('하셔서', 1)\n",
      "882 ('부탁드릴게요', 1)\n",
      "883 ('차라리', 1)\n",
      "884 ('파는거면', 1)\n",
      "885 ('당장', 1)\n",
      "886 ('사겠는데', 1)\n",
      "887 ('그것', 1)\n",
      "888 ('아니라서', 1)\n",
      "889 ('하기가', 1)\n",
      "890 ('어렵네요', 1)\n",
      "891 ('파란', 1)\n",
      "892 ('안고다니구', 1)\n",
      "893 ('탈때', 1)\n",
      "894 ('쥐어주니', 1)\n",
      "895 ('타길래', 1)\n",
      "896 ('들고', 1)\n",
      "897 ('나갔다', 1)\n",
      "898 ('그만', 1)\n",
      "899 ('그래도', 1)\n",
      "900 ('통해', 1)\n",
      "901 ('먹고있는데', 1)\n",
      "902 ('애용', 1)\n",
      "903 ('할테니', 1)\n",
      "904 ('알아봐주세요', 1)\n",
      "905 ('하게되', 1)\n",
      "906 ('면', 1)\n",
      "907 ('맨날', 1)\n",
      "908 ('노래', 1)\n",
      "909 ('부르고', 1)\n",
      "910 ('다닐게요', 1)\n",
      "911 ('정말', 1)\n",
      "912 ('감사합니다', 1)\n",
      "913 ('박스', 1)\n",
      "914 ('중지', 1)\n",
      "915 ('오질', 1)\n",
      "916 ('되는게', 1)\n",
      "917 ('금요일', 1)\n",
      "918 ('있거든요', 1)\n",
      "919 ('안된다면', 1)\n",
      "920 ('신규', 1)\n",
      "921 ('지인', 1)\n",
      "922 ('아이디', 1)\n",
      "923 ('없으면', 1)\n",
      "924 ('할인', 1)\n",
      "925 ('사제품', 1)\n",
      "926 ('프로', 1)\n",
      "927 ('해주던데', 1)\n",
      "928 ('이었습니다', 1)\n",
      "929 ('포장', 1)\n",
      "930 ('뜯고', 1)\n",
      "931 ('찍은', 1)\n",
      "932 ('사진', 1)\n",
      "933 ('가끔', 1)\n",
      "934 ('성의', 1)\n",
      "935 ('담아', 1)\n",
      "936 ('보낼', 1)\n",
      "937 ('있더군요', 1)\n",
      "938 ('먹다', 1)\n",
      "939 ('싸준거', 1)\n",
      "940 ('같아서', 1)\n",
      "941 ('좋지', 1)\n",
      "942 ('제작', 1)\n",
      "943 ('과정', 1)\n",
      "944 ('그럴수', 1)\n",
      "945 ('있겠지만', 1)\n",
      "946 ('신경', 1)\n",
      "947 ('쓰셔야', 1)\n",
      "948 ('할거', 1)\n",
      "949 ('거부', 1)\n",
      "950 ('바랍니다', 1)\n",
      "951 ('잘못', 1)\n",
      "952 ('봐두', 1)\n",
      "953 ('최종', 1)\n",
      "954 ('까지인가요', 1)\n",
      "955 ('정확', 1)\n",
      "956 ('국내', 1)\n",
      "957 ('산', 1)\n",
      "958 ('쓰나요', 1)\n",
      "959 ('치즈', 1)\n",
      "960 ('어떤', 1)\n",
      "961 ('되네요', 1)\n",
      "962 ('이', 1)\n",
      "963 ('포함', 1)\n",
      "964 ('말아주세요', 1)\n",
      "965 ('요즘', 1)\n",
      "966 ('자주', 1)\n",
      "967 ('내용물', 1)\n",
      "968 ('넘쳐있어요', 1)\n",
      "969 ('짜증', 1)\n",
      "970 ('이나', 1)\n"
     ]
    }
   ],
   "source": [
    "# word-index사전을 만든다. \n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "wordId_dic = {}\n",
    "idx = 0\n",
    "for key in keys:\n",
    "    idx += 1\n",
    "    print(idx , key)\n",
    "    wordId_dic[key[0]] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sen = []\n",
    "\n",
    "# 모든 문장을 index로 바꾼다. \n",
    "for text in lines[0:300]:\n",
    "    sen_idx = [wordId_dic[w] for w in text2seq(text)]\n",
    "    all_sen.append(sen_idx)\n",
    "all_sen_arr = np.array(all_sen)\n",
    "\n",
    "X_train_all = all_sen_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류한 정답파일을 만들어 읽어온다. \n",
    "fp2 = codecs.open(\"yang_class.txt\", \"r\")\n",
    "classes = fp2.readlines()\n",
    "cls26 = []\n",
    "class_dic = {}\n",
    "idx = 0\n",
    "\n",
    "for cls in classes:\n",
    "    cls = cls.replace('\\n','')\n",
    "    cls26.append(cls)\n",
    "    \n",
    "    if not (cls in class_dic):\n",
    "        class_dic[cls] = idx\n",
    "        idx += 1\n",
    "        \n",
    "fp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 미배송 0\n",
      "2 배송일정 1\n",
      "3 미배송 0\n",
      "4 배송장소 2\n",
      "5 미배송 0\n",
      "6 배송일정 1\n",
      "7 배송방법 3\n",
      "8 주문 4\n",
      "9 배송방법 3\n",
      "10 배송방법 3\n",
      "11 배송중단 5\n",
      "12 구매문의 6\n",
      "13 미배송 0\n",
      "14 배송연기 7\n",
      "15 배송오류 8\n",
      "16 배송일정 1\n",
      "17 가방 9\n",
      "18 배송장소 2\n",
      "19 미배송 0\n",
      "20 미배송 0\n",
      "21 배송변경 10\n",
      "22 가방 9\n",
      "23 배송일정 1\n",
      "24 결제오류 11\n",
      "25 결제오류 11\n",
      "26 상품문의 12\n",
      "27 인사 13\n",
      "28 배송일정 1\n",
      "29 배송신청 14\n",
      "30 배송일정 1\n",
      "31 배송장소 2\n",
      "32 상품변경 15\n",
      "33 배송장소 2\n",
      "34 상품문의 12\n",
      "35 상품문의 12\n",
      "36 상품변경 15\n",
      "37 배송문의 16\n",
      "38 미배송 0\n",
      "39 미배송 0\n",
      "40 교환환불 17\n",
      "41 이벤트 18\n",
      "42 시스템 19\n",
      "43 상품문의 12\n",
      "44 상품문의 12\n",
      "45 상품문의 12\n",
      "46 가방 9\n",
      "47 이벤트 18\n",
      "48 가방 9\n",
      "49 배송일정 1\n",
      "50 배송일정 1\n",
      "51 배송상품 20\n",
      "52 배송일정 1\n",
      "53 상품불량 21\n",
      "54 배송문의 16\n",
      "55 배송일정 1\n",
      "56 배송오류 8\n",
      "57 배송일정 1\n",
      "58 배송일정 1\n",
      "59 가방 9\n",
      "60 교환환불 17\n",
      "61 주문변경 22\n",
      "62 상품문의 12\n",
      "63 배송장소 2\n",
      "64 배송일정 1\n",
      "65 배송장소 2\n",
      "66 배송방법 3\n",
      "67 취소해지 23\n",
      "68 취소해지 23\n",
      "69 배송장소 2\n",
      "70 배송장소 2\n",
      "71 교환환불 17\n",
      "72 상품문의 12\n",
      "73 배송일정 1\n",
      "74 배송일정 1\n",
      "75 상품문의 12\n",
      "76 상품불량 21\n",
      "77 상품문의 12\n",
      "78 배송오류 8\n",
      "79 배송오류 8\n",
      "80 배송일정 1\n",
      "81 주문변경 22\n",
      "82 가방 9\n",
      "83 주문 4\n",
      "84 가방 9\n",
      "85 미배송 0\n",
      "86 미배송 0\n",
      "87 상품문의 12\n",
      "88 배송일정 1\n",
      "89 가방 9\n",
      "90 이벤트 18\n",
      "91 배송오류 8\n",
      "92 이벤트 18\n",
      "93 배송일정 1\n",
      "94 취소해지 23\n",
      "95 배송일정 1\n",
      "96 가방 9\n",
      "97 가방 9\n",
      "98 배송상품 20\n",
      "99 상품불량 21\n",
      "100 배송일정 1\n",
      "101 배송상품 20\n",
      "102 배송일정 1\n",
      "103 담당자 24\n",
      "104 가방 9\n",
      "105 배송일정 1\n",
      "106 가방 9\n",
      "107 배송일정 1\n",
      "108 배송오류 8\n",
      "109 미배송 0\n",
      "110 배송일정 1\n",
      "111 상품불량 21\n",
      "112 서비스 25\n",
      "113 배송일정 1\n",
      "114 취소해지 23\n",
      "115 배송장소 2\n",
      "116 상품문의 12\n",
      "117 취소해지 23\n",
      "118 배송장소 2\n",
      "119 가방 9\n",
      "120 상품문의 12\n",
      "121 상품문의 12\n",
      "122 상품문의 12\n",
      "123 취소해지 23\n",
      "124 취소해지 23\n",
      "125 이벤트 18\n",
      "126 담당자 24\n",
      "127 담당자 24\n",
      "128 상품문의 12\n",
      "129 이벤트 18\n",
      "130 배송일정 1\n",
      "131 배송일정 1\n",
      "132 배송일정 1\n",
      "133 취소해지 23\n",
      "134 미배송 0\n",
      "135 배송일정 1\n",
      "136 배송오류 8\n",
      "137 배송일정 1\n",
      "138 배송변경 10\n",
      "139 배송변경 10\n",
      "140 이벤트 18\n",
      "141 배송일정 1\n",
      "142 주문 4\n",
      "143 상품문의 12\n",
      "144 배송문의 16\n",
      "145 상품문의 12\n",
      "146 상품문의 12\n",
      "147 미배송 0\n",
      "148 상품문의 12\n",
      "149 배송일정 1\n",
      "150 이벤트 18\n",
      "151 미배송 0\n",
      "152 배송일정 1\n",
      "153 배송일정 1\n",
      "154 구매문의 6\n",
      "155 구매문의 6\n",
      "156 배송오류 8\n",
      "157 배송일정 1\n",
      "158 배송일정 1\n",
      "159 배송문의 16\n",
      "160 배송오류 8\n",
      "161 배송변경 10\n",
      "162 배송일정 1\n",
      "163 미배송 0\n",
      "164 취소해지 23\n",
      "165 상품불량 21\n",
      "166 상품문의 12\n",
      "167 배송일정 1\n",
      "168 배송변경 10\n",
      "169 배송오류 8\n",
      "170 이벤트 18\n",
      "171 배송변경 10\n",
      "172 배송일정 1\n",
      "173 배송장소 2\n",
      "174 배송장소 2\n",
      "175 배송일정 1\n",
      "176 배송일정 1\n",
      "177 배송오류 8\n",
      "178 배송일정 1\n",
      "179 배송문의 16\n",
      "180 배송일정 1\n",
      "181 배송일정 1\n",
      "182 배송일정 1\n",
      "183 상품문의 12\n",
      "184 배송변경 10\n",
      "185 상품문의 12\n",
      "186 상품문의 12\n",
      "187 배송문의 16\n",
      "188 취소해지 23\n",
      "189 미배송 0\n",
      "190 이벤트 18\n",
      "191 배송상품 20\n",
      "192 취소해지 23\n",
      "193 배송오류 8\n",
      "194 배송일정 1\n",
      "195 배송일정 1\n",
      "196 상품문의 12\n",
      "197 상품문의 12\n",
      "198 배송일정 1\n",
      "199 취소해지 23\n",
      "200 상품불량 21\n"
     ]
    }
   ],
   "source": [
    "cls_idxes = []\n",
    "index = 0 \n",
    "\n",
    "# Y_train구하기 \n",
    "for text in cls26:\n",
    "    idx = class_dic[text]\n",
    "    index += 1\n",
    "    print(index , text , idx)\n",
    "    cls_idxes.append(idx) \n",
    "    \n",
    "cls_idxes_arr = np.array(cls_idxes)\n",
    "Y_train_all = cls_idxes_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 \n",
    "\n",
    "# LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding , Dropout, Activation\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "category = np.max(Y_train_all) + 1\n",
    "\n",
    "X_train = X_train_all\n",
    "X_test = X_train_all\n",
    "Y_train = Y_train_all\n",
    "Y_test = Y_train_all\n",
    "\n",
    "# 데이터 전처리\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.62 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Yohan\\anaconda3\\envs\\tensorflow_lab\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 3.2406 - accuracy: 0.1250 - val_loss: 3.2082 - val_accuracy: 0.2400\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 3.1683 - accuracy: 0.2400 - val_loss: 3.1411 - val_accuracy: 0.2400\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 3.0781 - accuracy: 0.2400 - val_loss: 3.0442 - val_accuracy: 0.2400\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 2.9751 - accuracy: 0.2400 - val_loss: 2.9299 - val_accuracy: 0.2400\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 821us/step - loss: 2.8781 - accuracy: 0.2400 - val_loss: 2.8455 - val_accuracy: 0.2400\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 2.8317 - accuracy: 0.2400 - val_loss: 2.8046 - val_accuracy: 0.2400\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 2.8015 - accuracy: 0.2400 - val_loss: 2.7747 - val_accuracy: 0.2400\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 2.7749 - accuracy: 0.2400 - val_loss: 2.7452 - val_accuracy: 0.2400\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 2.7450 - accuracy: 0.2400 - val_loss: 2.7228 - val_accuracy: 0.2400\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 2.7173 - accuracy: 0.2400 - val_loss: 2.7096 - val_accuracy: 0.2400\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 851us/step - loss: 2.7086 - accuracy: 0.2400 - val_loss: 2.7002 - val_accuracy: 0.2400\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 2.6993 - accuracy: 0.2400 - val_loss: 2.6912 - val_accuracy: 0.2400\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 2.6886 - accuracy: 0.2400 - val_loss: 2.6809 - val_accuracy: 0.2400\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 816us/step - loss: 2.6795 - accuracy: 0.2400 - val_loss: 2.6706 - val_accuracy: 0.2400\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 2.6695 - accuracy: 0.2400 - val_loss: 2.6615 - val_accuracy: 0.2400\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 947us/step - loss: 2.6599 - accuracy: 0.2400 - val_loss: 2.6534 - val_accuracy: 0.2400\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 2.6561 - accuracy: 0.2400 - val_loss: 2.6459 - val_accuracy: 0.2400\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 821us/step - loss: 2.6475 - accuracy: 0.2400 - val_loss: 2.6378 - val_accuracy: 0.2400\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 831us/step - loss: 2.6389 - accuracy: 0.2400 - val_loss: 2.6289 - val_accuracy: 0.2400\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 2.6309 - accuracy: 0.2400 - val_loss: 2.6195 - val_accuracy: 0.2400\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 821us/step - loss: 2.6216 - accuracy: 0.2400 - val_loss: 2.6096 - val_accuracy: 0.2400\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 806us/step - loss: 2.6103 - accuracy: 0.2400 - val_loss: 2.5989 - val_accuracy: 0.2450\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 2.5991 - accuracy: 0.2400 - val_loss: 2.5865 - val_accuracy: 0.2450\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 831us/step - loss: 2.5852 - accuracy: 0.2400 - val_loss: 2.5723 - val_accuracy: 0.2450\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 2.5694 - accuracy: 0.2400 - val_loss: 2.5562 - val_accuracy: 0.2500\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 801us/step - loss: 2.5556 - accuracy: 0.2450 - val_loss: 2.5384 - val_accuracy: 0.2550\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 2.5373 - accuracy: 0.2500 - val_loss: 2.5177 - val_accuracy: 0.2550\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 2.5181 - accuracy: 0.2500 - val_loss: 2.4950 - val_accuracy: 0.2600\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 880us/step - loss: 2.4909 - accuracy: 0.2650 - val_loss: 2.4696 - val_accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 893us/step - loss: 2.4674 - accuracy: 0.2850 - val_loss: 2.4391 - val_accuracy: 0.3350\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 2.4344 - accuracy: 0.3100 - val_loss: 2.4038 - val_accuracy: 0.3450\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 2.3975 - accuracy: 0.3200 - val_loss: 2.3659 - val_accuracy: 0.3850\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 831us/step - loss: 2.3642 - accuracy: 0.3400 - val_loss: 2.3262 - val_accuracy: 0.4150\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 930us/step - loss: 2.3191 - accuracy: 0.4000 - val_loss: 2.2865 - val_accuracy: 0.4100\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 2.2800 - accuracy: 0.4100 - val_loss: 2.2409 - val_accuracy: 0.4100\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 799us/step - loss: 2.2344 - accuracy: 0.4100 - val_loss: 2.1965 - val_accuracy: 0.4000\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 2.1914 - accuracy: 0.4050 - val_loss: 2.1486 - val_accuracy: 0.4150\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 2.1458 - accuracy: 0.4100 - val_loss: 2.1015 - val_accuracy: 0.4150\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 915us/step - loss: 2.1073 - accuracy: 0.4150 - val_loss: 2.0594 - val_accuracy: 0.4100\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 2.0617 - accuracy: 0.4200 - val_loss: 2.0191 - val_accuracy: 0.4200\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 2.0043 - accuracy: 0.4250 - val_loss: 1.9610 - val_accuracy: 0.4300\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 1.9667 - accuracy: 0.4250 - val_loss: 1.9079 - val_accuracy: 0.4400\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 1.9099 - accuracy: 0.4500 - val_loss: 1.8809 - val_accuracy: 0.4400\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 1.8671 - accuracy: 0.4500 - val_loss: 1.8068 - val_accuracy: 0.4750\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 910us/step - loss: 1.8171 - accuracy: 0.4600 - val_loss: 1.7567 - val_accuracy: 0.4900\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 1.7583 - accuracy: 0.5050 - val_loss: 1.7189 - val_accuracy: 0.5050\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 1.7168 - accuracy: 0.5200 - val_loss: 1.6609 - val_accuracy: 0.5300\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 1.6512 - accuracy: 0.5250 - val_loss: 1.6059 - val_accuracy: 0.5550\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 1.6190 - accuracy: 0.5300 - val_loss: 1.5545 - val_accuracy: 0.5750\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 1.5666 - accuracy: 0.5700 - val_loss: 1.5076 - val_accuracy: 0.6050\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 1.5261 - accuracy: 0.6150 - val_loss: 1.4616 - val_accuracy: 0.6500\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 841us/step - loss: 1.4726 - accuracy: 0.6250 - val_loss: 1.4097 - val_accuracy: 0.6750\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 952us/step - loss: 1.4223 - accuracy: 0.6600 - val_loss: 1.3576 - val_accuracy: 0.6950\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 1.3761 - accuracy: 0.6800 - val_loss: 1.3093 - val_accuracy: 0.6950\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 1.3350 - accuracy: 0.6850 - val_loss: 1.2635 - val_accuracy: 0.7100\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 1.2738 - accuracy: 0.7000 - val_loss: 1.2173 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 1.2374 - accuracy: 0.7100 - val_loss: 1.1740 - val_accuracy: 0.7150\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 1.2157 - accuracy: 0.6950 - val_loss: 1.1292 - val_accuracy: 0.7250\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 890us/step - loss: 1.1579 - accuracy: 0.7150 - val_loss: 1.0900 - val_accuracy: 0.7400\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.79 - 0s 875us/step - loss: 1.1074 - accuracy: 0.7500 - val_loss: 1.0503 - val_accuracy: 0.7600\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 1.0724 - accuracy: 0.7500 - val_loss: 1.0090 - val_accuracy: 0.7650\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 1.0207 - accuracy: 0.7550 - val_loss: 0.9754 - val_accuracy: 0.7800\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 861us/step - loss: 0.9972 - accuracy: 0.7800 - val_loss: 0.9398 - val_accuracy: 0.8050\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 942us/step - loss: 0.9645 - accuracy: 0.7800 - val_loss: 0.9049 - val_accuracy: 0.8200\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 893us/step - loss: 0.9199 - accuracy: 0.8200 - val_loss: 0.8681 - val_accuracy: 0.8300\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 0.8949 - accuracy: 0.8300 - val_loss: 0.8396 - val_accuracy: 0.8500\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 801us/step - loss: 0.8587 - accuracy: 0.8150 - val_loss: 0.8116 - val_accuracy: 0.8750\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 880us/step - loss: 0.8374 - accuracy: 0.8400 - val_loss: 0.7733 - val_accuracy: 0.8700\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.8073 - accuracy: 0.8350 - val_loss: 0.7509 - val_accuracy: 0.8800\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.7980 - accuracy: 0.8400 - val_loss: 0.7381 - val_accuracy: 0.8850\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 806us/step - loss: 0.7625 - accuracy: 0.8850 - val_loss: 0.6941 - val_accuracy: 0.9000\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.7298 - accuracy: 0.8900 - val_loss: 0.6693 - val_accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 0.7086 - accuracy: 0.8700 - val_loss: 0.6447 - val_accuracy: 0.9100\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 955us/step - loss: 0.6839 - accuracy: 0.8850 - val_loss: 0.6351 - val_accuracy: 0.9000\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.6519 - accuracy: 0.9000 - val_loss: 0.6104 - val_accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.6311 - accuracy: 0.9150 - val_loss: 0.5795 - val_accuracy: 0.9100\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 0s 960us/step - loss: 0.6116 - accuracy: 0.8950 - val_loss: 0.5578 - val_accuracy: 0.9150\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.5819 - accuracy: 0.9100 - val_loss: 0.5398 - val_accuracy: 0.9150\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 0s 861us/step - loss: 0.5714 - accuracy: 0.9050 - val_loss: 0.5233 - val_accuracy: 0.9200\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.5589 - accuracy: 0.9150 - val_loss: 0.5078 - val_accuracy: 0.9300\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.5399 - accuracy: 0.9050 - val_loss: 0.4884 - val_accuracy: 0.9300\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 0.5272 - accuracy: 0.9250 - val_loss: 0.4677 - val_accuracy: 0.9300\n",
      "Epoch 83/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.4918 - accuracy: 0.9200 - val_loss: 0.4507 - val_accuracy: 0.9350\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.4729 - accuracy: 0.9300 - val_loss: 0.4365 - val_accuracy: 0.9350\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 0s 915us/step - loss: 0.4677 - accuracy: 0.9300 - val_loss: 0.4242 - val_accuracy: 0.9450\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.4519 - accuracy: 0.9250 - val_loss: 0.4102 - val_accuracy: 0.9450\n",
      "Epoch 87/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 0.4347 - accuracy: 0.9300 - val_loss: 0.3965 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 0s 801us/step - loss: 0.4312 - accuracy: 0.9400 - val_loss: 0.3801 - val_accuracy: 0.9500\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 0s 816us/step - loss: 0.4139 - accuracy: 0.9400 - val_loss: 0.3662 - val_accuracy: 0.9500\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.4023 - accuracy: 0.9400 - val_loss: 0.3543 - val_accuracy: 0.9500\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 0s 900us/step - loss: 0.3810 - accuracy: 0.9350 - val_loss: 0.3449 - val_accuracy: 0.9550\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 0s 925us/step - loss: 0.3723 - accuracy: 0.9450 - val_loss: 0.3345 - val_accuracy: 0.9550\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.9500 - val_loss: 0.3215 - val_accuracy: 0.9550\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 0s 895us/step - loss: 0.3584 - accuracy: 0.9400 - val_loss: 0.3086 - val_accuracy: 0.9550\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 0s 985us/step - loss: 0.3427 - accuracy: 0.9550 - val_loss: 0.2983 - val_accuracy: 0.9600\n",
      "Epoch 96/200\n",
      "200/200 [==============================] - 0s 885us/step - loss: 0.3395 - accuracy: 0.9450 - val_loss: 0.2905 - val_accuracy: 0.9600\n",
      "Epoch 97/200\n",
      "200/200 [==============================] - 0s 831us/step - loss: 0.3270 - accuracy: 0.9450 - val_loss: 0.2824 - val_accuracy: 0.9600\n",
      "Epoch 98/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.3138 - accuracy: 0.9550 - val_loss: 0.2757 - val_accuracy: 0.9600\n",
      "Epoch 99/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.2997 - accuracy: 0.9550 - val_loss: 0.2693 - val_accuracy: 0.9600\n",
      "Epoch 100/200\n",
      "200/200 [==============================] - 0s 937us/step - loss: 0.3048 - accuracy: 0.9600 - val_loss: 0.2596 - val_accuracy: 0.9600\n",
      "Epoch 101/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.9550 - val_loss: 0.2492 - val_accuracy: 0.9600\n",
      "Epoch 102/200\n",
      "200/200 [==============================] - 0s 945us/step - loss: 0.2927 - accuracy: 0.9550 - val_loss: 0.2426 - val_accuracy: 0.9600\n",
      "Epoch 103/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.2724 - accuracy: 0.9650 - val_loss: 0.2353 - val_accuracy: 0.9600\n",
      "Epoch 104/200\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.96 - 0s 858us/step - loss: 0.2616 - accuracy: 0.9600 - val_loss: 0.2304 - val_accuracy: 0.9600\n",
      "Epoch 105/200\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.2550 - accuracy: 0.9600 - val_loss: 0.2248 - val_accuracy: 0.9600\n",
      "Epoch 106/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9600 - val_loss: 0.2169 - val_accuracy: 0.9600\n",
      "Epoch 107/200\n",
      "200/200 [==============================] - 0s 994us/step - loss: 0.2424 - accuracy: 0.9550 - val_loss: 0.2089 - val_accuracy: 0.9650\n",
      "Epoch 108/200\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.2361 - accuracy: 0.9600 - val_loss: 0.2023 - val_accuracy: 0.9650\n",
      "Epoch 109/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9600 - val_loss: 0.1969 - val_accuracy: 0.9650\n",
      "Epoch 110/200\n",
      "200/200 [==============================] - 0s 997us/step - loss: 0.2254 - accuracy: 0.9650 - val_loss: 0.1930 - val_accuracy: 0.9650\n",
      "Epoch 111/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9650 - val_loss: 0.1889 - val_accuracy: 0.9650\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 962us/step - loss: 0.2114 - accuracy: 0.9600 - val_loss: 0.1830 - val_accuracy: 0.9700\n",
      "Epoch 113/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.2130 - accuracy: 0.9600 - val_loss: 0.1788 - val_accuracy: 0.9750\n",
      "Epoch 114/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.2009 - accuracy: 0.9650 - val_loss: 0.1740 - val_accuracy: 0.9800\n",
      "Epoch 115/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.1928 - accuracy: 0.9650 - val_loss: 0.1686 - val_accuracy: 0.9800\n",
      "Epoch 116/200\n",
      "200/200 [==============================] - 0s 875us/step - loss: 0.1915 - accuracy: 0.9700 - val_loss: 0.1633 - val_accuracy: 0.9800\n",
      "Epoch 117/200\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.1922 - accuracy: 0.9700 - val_loss: 0.1598 - val_accuracy: 0.9750\n",
      "Epoch 118/200\n",
      "200/200 [==============================] - 0s 875us/step - loss: 0.1829 - accuracy: 0.9750 - val_loss: 0.1587 - val_accuracy: 0.9800\n",
      "Epoch 119/200\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.1848 - accuracy: 0.9650 - val_loss: 0.1528 - val_accuracy: 0.9850\n",
      "Epoch 120/200\n",
      "200/200 [==============================] - 0s 945us/step - loss: 0.1745 - accuracy: 0.9750 - val_loss: 0.1476 - val_accuracy: 0.9850\n",
      "Epoch 121/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.1697 - accuracy: 0.9750 - val_loss: 0.1443 - val_accuracy: 0.9850\n",
      "Epoch 122/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9800 - val_loss: 0.1400 - val_accuracy: 0.9850\n",
      "Epoch 123/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9800 - val_loss: 0.1365 - val_accuracy: 0.9850\n",
      "Epoch 124/200\n",
      "200/200 [==============================] - 0s 932us/step - loss: 0.1580 - accuracy: 0.9900 - val_loss: 0.1338 - val_accuracy: 0.9850\n",
      "Epoch 125/200\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.1604 - accuracy: 0.9700 - val_loss: 0.1305 - val_accuracy: 0.9850\n",
      "Epoch 126/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.1516 - accuracy: 0.9800 - val_loss: 0.1262 - val_accuracy: 0.9950\n",
      "Epoch 127/200\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.1583 - accuracy: 0.9750 - val_loss: 0.1226 - val_accuracy: 0.9950\n",
      "Epoch 128/200\n",
      "200/200 [==============================] - 0s 890us/step - loss: 0.1456 - accuracy: 0.9850 - val_loss: 0.1199 - val_accuracy: 0.9950\n",
      "Epoch 129/200\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.1388 - accuracy: 0.9750 - val_loss: 0.1182 - val_accuracy: 0.9950\n",
      "Epoch 130/200\n",
      "200/200 [==============================] - 0s 895us/step - loss: 0.1373 - accuracy: 0.9850 - val_loss: 0.1157 - val_accuracy: 0.9950\n",
      "Epoch 131/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.1354 - accuracy: 0.9850 - val_loss: 0.1131 - val_accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.1312 - accuracy: 0.9850 - val_loss: 0.1099 - val_accuracy: 0.9950\n",
      "Epoch 133/200\n",
      "200/200 [==============================] - 0s 955us/step - loss: 0.1277 - accuracy: 0.9900 - val_loss: 0.1072 - val_accuracy: 0.9950\n",
      "Epoch 134/200\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.1274 - accuracy: 0.9800 - val_loss: 0.1042 - val_accuracy: 0.9950\n",
      "Epoch 135/200\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.1361 - accuracy: 0.9800 - val_loss: 0.1031 - val_accuracy: 0.9950\n",
      "Epoch 136/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9800 - val_loss: 0.1020 - val_accuracy: 0.9950\n",
      "Epoch 137/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.1243 - accuracy: 0.9900 - val_loss: 0.0993 - val_accuracy: 0.9950\n",
      "Epoch 138/200\n",
      "200/200 [==============================] - 0s 863us/step - loss: 0.1162 - accuracy: 0.9900 - val_loss: 0.0961 - val_accuracy: 0.9950\n",
      "Epoch 139/200\n",
      "200/200 [==============================] - 0s 913us/step - loss: 0.1135 - accuracy: 0.9900 - val_loss: 0.0933 - val_accuracy: 0.9950\n",
      "Epoch 140/200\n",
      "200/200 [==============================] - 0s 853us/step - loss: 0.1058 - accuracy: 0.9900 - val_loss: 0.0906 - val_accuracy: 0.9950\n",
      "Epoch 141/200\n",
      "200/200 [==============================] - 0s 890us/step - loss: 0.1059 - accuracy: 0.9900 - val_loss: 0.0883 - val_accuracy: 0.9950\n",
      "Epoch 142/200\n",
      "200/200 [==============================] - 0s 890us/step - loss: 0.1082 - accuracy: 0.9850 - val_loss: 0.0870 - val_accuracy: 0.9950\n",
      "Epoch 143/200\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.1038 - accuracy: 0.9850 - val_loss: 0.0871 - val_accuracy: 0.9950\n",
      "Epoch 144/200\n",
      "200/200 [==============================] - 0s 955us/step - loss: 0.1037 - accuracy: 0.9850 - val_loss: 0.0868 - val_accuracy: 0.9950\n",
      "Epoch 145/200\n",
      "200/200 [==============================] - 0s 870us/step - loss: 0.1028 - accuracy: 0.9950 - val_loss: 0.0840 - val_accuracy: 0.9950\n",
      "Epoch 146/200\n",
      "200/200 [==============================] - 0s 942us/step - loss: 0.0972 - accuracy: 0.9950 - val_loss: 0.0802 - val_accuracy: 0.9950\n",
      "Epoch 147/200\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.99 - 0s 910us/step - loss: 0.0934 - accuracy: 0.9900 - val_loss: 0.0776 - val_accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.1016 - accuracy: 0.9850 - val_loss: 0.0758 - val_accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.0914 - accuracy: 0.9900 - val_loss: 0.0749 - val_accuracy: 0.9950\n",
      "Epoch 150/200\n",
      "200/200 [==============================] - 0s 900us/step - loss: 0.0871 - accuracy: 0.9950 - val_loss: 0.0750 - val_accuracy: 0.9950\n",
      "Epoch 151/200\n",
      "200/200 [==============================] - 0s 838us/step - loss: 0.0887 - accuracy: 0.9900 - val_loss: 0.0747 - val_accuracy: 0.9950\n",
      "Epoch 152/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.0877 - accuracy: 0.9850 - val_loss: 0.0742 - val_accuracy: 0.9950\n",
      "Epoch 153/200\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.0913 - accuracy: 0.9900 - val_loss: 0.0722 - val_accuracy: 0.9950\n",
      "Epoch 154/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.0820 - accuracy: 0.9950 - val_loss: 0.0691 - val_accuracy: 0.9950\n",
      "Epoch 155/200\n",
      "200/200 [==============================] - 0s 905us/step - loss: 0.0842 - accuracy: 0.9950 - val_loss: 0.0665 - val_accuracy: 0.9950\n",
      "Epoch 156/200\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.0829 - accuracy: 0.9950 - val_loss: 0.0646 - val_accuracy: 0.9950\n",
      "Epoch 157/200\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9950\n",
      "Epoch 158/200\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.0764 - accuracy: 0.9950 - val_loss: 0.0624 - val_accuracy: 0.9950\n",
      "Epoch 159/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.0804 - accuracy: 0.9950 - val_loss: 0.0612 - val_accuracy: 0.9950\n",
      "Epoch 160/200\n",
      "200/200 [==============================] - 0s 990us/step - loss: 0.0761 - accuracy: 0.9950 - val_loss: 0.0601 - val_accuracy: 0.9950\n",
      "Epoch 161/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.0766 - accuracy: 0.9950 - val_loss: 0.0588 - val_accuracy: 0.9950\n",
      "Epoch 162/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "200/200 [==============================] - 0s 868us/step - loss: 0.0736 - accuracy: 0.9950 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 1.00 - 0s 920us/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 836us/step - loss: 0.0683 - accuracy: 0.9950 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "200/200 [==============================] - 0s 913us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.0617 - accuracy: 0.9950 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "200/200 [==============================] - 0s 816us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.0578 - accuracy: 0.9950 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "200/200 [==============================] - 0s 813us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "200/200 [==============================] - 0s 935us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "200/200 [==============================] - 0s 816us/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "200/200 [==============================] - 0s 823us/step - loss: 0.0517 - accuracy: 0.9950 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "200/200 [==============================] - 0s 905us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "200/200 [==============================] - 0s 861us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "200/200 [==============================] - 0s 821us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "200/200 [==============================] - 0s 808us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "200/200 [==============================] - 0s 826us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "200/200 [==============================] - 0s 818us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "200/200 [==============================] - 0s 811us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "200/200 [==============================] - 0s 816us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(971, 200))\n",
    "model.add(Dropout(0.62))\n",
    "model.add(Conv1D(64, 5, padding='valid', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(55))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# 모델의 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# 모델의 실행\n",
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=200, \n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 203us/step\n",
      "\n",
      " Test Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1]))\n",
    "\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = np.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
